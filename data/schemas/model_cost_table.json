{
  "version": "1.3",
  "description": "Model pricing tiers for cost estimation in Task Assessor (USD per 1M tokens; cache-miss unless noted)",
  "last_updated": "2025-12-14",
  "tiers": {
    "cheap": {
      "name": "Budget (fast, small, high-volume)",
      "examples": [
        "OpenAI gpt-5-nano",
        "OpenAI gpt-4.1-nano",
        "Anthropic Claude Haiku 4.5",
        "Google Gemini 2.5 Flash-Lite",
        "DeepSeek deepseek-chat",
        "Mistral Ministral 8B",
        "Qwen 2.5 7B",
        "Phi-4 Mini"
      ],
      "input_cost_per_1m_tokens": 0.10,
      "output_cost_per_1m_tokens": 0.50,
      "capabilities": [
        "simple_extraction",
        "basic_formatting",
        "text_manipulation",
        "template_filling",
        "light_summarization"
      ],
      "limitations": [
        "limited_reasoning",
        "weak planning",
        "higher_error_rate_on_edge_cases"
      ]
    },
    "medium": {
      "name": "Capable (default workhorse)",
      "examples": [
        "OpenAI gpt-5-mini",
        "OpenAI gpt-4o-mini",
        "OpenAI gpt-4.1-mini",
        "Google Gemini 2.5 Flash",
        "DeepSeek deepseek-reasoner",
        "Mistral Large (24B)",
        "Qwen 2.5 72B",
        "Kimi K2",
        "Mixtral 8x22B",
        "Llama 3.1 70B"
      ],
      "input_cost_per_1m_tokens": 0.40,
      "output_cost_per_1m_tokens": 2.50,
      "capabilities": [
        "code_generation",
        "data_analysis",
        "multi_step_reasoning",
        "api_integration",
        "document_generation",
        "spreadsheet_formulas"
      ],
      "limitations": [
        "may_struggle_with_high-stakes nuance",
        "reasoning depth below frontier models"
      ]
    },
    "expensive": {
      "name": "Frontier (best quality / hardest tasks)",
      "examples": [
        "OpenAI gpt-5.1 / gpt-5.2",
        "OpenAI gpt-4o",
        "OpenAI gpt-4.1",
        "Anthropic Claude Sonnet 4.5",
        "Anthropic Claude Opus 4.5",
        "Google Gemini 2.5 Pro",
        "Google Gemini 3 Pro Preview",
        "DeepSeek-R1 (hosted)",
        "Qwen 2.5-Max",
        "Llama 3.1 405B"
      ],
      "input_cost_per_1m_tokens": 2.00,
      "output_cost_per_1m_tokens": 10.00,
      "capabilities": [
        "complex_reasoning",
        "nuanced_writing",
        "difficult_edge_cases",
        "creative_problem_solving",
        "long_context",
        "high-reliability_tool_use"
      ],
      "limitations": []
    }
  },
  "open_source_notes": {
    "pricing_model": "Costs reflect hosted inference (Together/Fireworks/Groq-class providers). Self-hosted costs depend on GPU, utilization, and batching.",
    "performance_meta": {
      "mistral": "Strong instruction-following and code; Mixtral remains a cost-efficient MoE workhorse.",
      "deepseek": "Best OSS reasoning-per-dollar; R1 competes with frontier models at lower cost.",
      "qwen": "Best multilingual OSS; 72B and Max variants used as GPT-4-class substitutes.",
      "kimi": "Very strong long-context reasoning; popular in agentic and research workflows.",
      "llama": "Ecosystem dominance; 70B widely deployed, 405B reserved for frontier self-hosting."
    }
  },
  "default_execution_tier": "medium",
  "overhead_multiplier": 1.3,
  "notes": {
    "default_tier": "Most production tasks should be executable by medium-tier models",
    "estimation_guidance": [
      "Prefer OSS medium-tier models for batch analytics and internal tooling.",
      "Use frontier models selectively for planning, synthesis, and user-facing outputs.",
      "Reasoning-specialized models (DeepSeek-R1, OpenAI o3) often outperform general models at similar cost."
    ]
  },
  "currency_conversion": {
    "INR_to_USD": 0.012,
    "GBP_to_USD": 1.27,
    "EUR_to_USD": 1.09,
    "AUD_to_USD": 0.66
  },
  "token_estimates_by_category": {
    "data_entry": {
      "input": 2000,
      "output": 5000
    },
    "data_transformation": {
      "input": 3000,
      "output": 8000
    },
    "data_visualization": {
      "input": 5000,
      "output": 15000
    },
    "spreadsheet_formula": {
      "input": 1500,
      "output": 3000
    },
    "document_conversion": {
      "input": 4000,
      "output": 12000
    },
    "code_generation": {
      "input": 8000,
      "output": 25000
    },
    "research_analysis": {
      "input": 15000,
      "output": 40000
    },
    "full_stack_development": {
      "input": 20000,
      "output": 60000
    },
    "web_scraping": {
      "input": 5000,
      "output": 20000
    },
    "automation": {
      "input": 6000,
      "output": 18000
    }
  }
}